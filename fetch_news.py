#!/usr/bin/env python3
"""
æ¯æ—¥ç®€æŠ¥ç”Ÿæˆè„šæœ¬
æŠ“å–RSSæºå¹¶ç”Ÿæˆç®€æŠ¥
"""

import feedparser
import html
from datetime import datetime
from urllib.parse import urlparse

RSS_SOURCES = {
    "æŠ€æœ¯èµ„è®¯": [
        {"name": "Hacker News", "url": "https://hnrss.org/frontpage", "limit": 5},
        {"name": "æå®¢å…¬å›­", "url": "https://www.geekpark.net/feed", "limit": 5},
        {"name": "36æ°ª", "url": "https://36kr.com/feed/", "limit": 5},
        {"name": "é’›åª’ä½“", "url": "https://www.tmtpost.com/feed", "limit": 5},
        {"name": "InfoQ", "url": "https://www.infoq.com/feed/", "limit": 5},
        {"name": "TechCrunch", "url": "https://techcrunch.com/feed/", "limit": 5},
        {"name": "The Verge", "url": "https://www.theverge.com/rss/index.xml", "limit": 5},
    ],
    "æŠ•èµ„/é‡‘è": [
        {"name": "åå°”è¡—è§é—»", "url": "https://wallstreetcn.com/rss", "limit": 5},
        {"name": "é›ªçƒAè‚¡", "url": "https://xueqiu.com/statuses/public_timeline?page=1&size=10&type=stock", "limit": 5},
        {"name": "è´¢æ–°ç½‘", "url": "http://www.caixin.com/atom.xml", "limit": 5},
        {"name": "ç»æµè§‚å¯ŸæŠ¥", "url": "https://www.eeo.com.cn/feed/", "limit": 5},
        {"name": "Bloomberg", "url": "https://feeds.bloomberg.com/markets/news.rss", "limit": 5},
    ],
    "AI/ç§‘æŠ€å‰æ²¿": [
        {"name": "OpenAI Blog", "url": "https://openai.com/blog/rss.xml", "limit": 5},
        {"name": "Anthropic Blog", "url": "https://www.anthropic.com/rss.xml", "limit": 5},
        {"name": "MIT Tech Review", "url": "https://www.technologyreview.com/feed/", "limit": 5},
        {"name": "Wired Tech", "url": "https://www.wired.com/feed/category/tech/latest/rss", "limit": 5},
    ],
}

def parse_rss(source):
    """è§£æå•ä¸ªRSSæº"""
    try:
        feed = feedparser.parse(source["url"])
        entries = []
        for entry in feed.entries[:source["limit"]]:
            title = html.unescape(entry.get("title", "æ— æ ‡é¢˜"))
            link = entry.get("link", "")
            
            # å°è¯•è·å–æ‘˜è¦
            if hasattr(entry, "summary"):
                summary = html.unescape(entry.summary)
                summary = summary[:200] + "..." if len(summary) > 200 else summary
            elif hasattr(entry, "description"):
                summary = html.unescape(entry.description)
                summary = summary[:200] + "..." if len(summary) > 200 else summary
            else:
                summary = ""
            
            entries.append({
                "title": title,
                "link": link,
                "summary": summary
            })
        return {"name": source["name"], "entries": entries, "error": None}
    except Exception as e:
        return {"name": source["name"], "entries": [], "error": str(e)}

def generate_briefing():
    """ç”Ÿæˆæ¯æ—¥ç®€æŠ¥"""
    date_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    briefing = f"ğŸ“° æ¯æ—¥ç®€æŠ¥ - {date_str}\n\n"
    
    total_items = 0
    
    for category, sources in RSS_SOURCES.items():
        briefing += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        briefing += f"ğŸ“‚ {category}\n"
        briefing += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        
        for source in sources:
            result = parse_rss(source)
            if result["error"]:
                briefing += f"âŒ {result['name']}: {result['error']}\n\n"
                continue
            
            if not result["entries"]:
                continue
                
            briefing += f"ğŸ”¹ {result['name']}\n"
            for entry in result["entries"]:
                briefing += f"  â€¢ {entry['title']}\n"
                briefing += f"    {entry['link']}\n"
            briefing += "\n"
            total_items += len(result["entries"])
    
    briefing += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    briefing += f"å…±æ”¶é›† {total_items} æ¡èµ„è®¯\n"
    briefing += f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%H:%M:%S')}"
    
    return briefing

if __name__ == "__main__":
    briefing = generate_briefing()
    print(briefing)
